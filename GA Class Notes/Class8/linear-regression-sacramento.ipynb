{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Linear Regression with Sacramento Real Estate Data\n",
    "\n",
    "_Authors: Matt Brems, Sam Stack, Justin Pounders, Jef fHale_\n",
    "\n",
    "---\n",
    "\n",
    "In this lab you will hone your exploratory data analysis (EDA) skills and practice constructing linear regressions using a dataset of Sacramento real estate sales.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read in the Sacramento housing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sac_csv = 'data/sacramento_real_estate_transactions.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Conduct exploratory data analysis on this dataset. \n",
    "\n",
    "#### Report any notable findings here and any steps you take to clean/process data.\n",
    "\n",
    "> **Note:** Many EDA checks should be done on every data set you handle. If you find yourself checking repeatedly for missing/corrupted data, it might be beneficial to have a function that you can reuse every time you're given new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Fun Fact:** Zip codes often have leading zeros — e.g., 02215 = Boston, MA — which will often get knocked off automatically by many software programs like Python or Excel. You can imagine that this could create some issues. _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Our goal will be to predict price. List variables in the dataset you think might be good predictors of price. \n",
    "\n",
    "For each of the numeric variables you believe might be a potential predictor in an regression model, generate a plot showing the relationship between the independent and dependent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you've finished cleaning or have made a good deal of progress cleaning, it's a good idea to save your work. For example:\n",
    "```python\n",
    "shd.to_csv('./datasets/sacramento_real_estate_transactions_Clean.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Which single numeric feature would likely be the best predictor of price? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Make a DataFrame *X* that consists of a single numeric column you chose above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Make a Series named _y_ that consists of only the 'price' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Use scikit-learn's LinearRegression class to instantiate and fit a model with just the one numeric column you think is the best predictor of price. \n",
    "\n",
    "This is simple linear regression because there is only one predictor column. \n",
    "\n",
    "> Note: Scikit-learn estimators expect a 2-dimensional predictor array because usually we have more than one predictor. Make yours 2-dimensional before fitting the model.\n",
    "\n",
    "To construct your model don't forget to load in the scikit-learn class and instantiate a model\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "# ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Use your model to make predict price for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Score your model on r-squared, mean_absolute_error, and root_mean_squared_error\n",
    "\n",
    "Feel free to make a function that accepts y_true and y_predicted and prints out the model's performance on all those metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Make a null-model that predicts the mean of `y_train`. One that has the mean as the predicted price. Score that model on the metrics above. Which model does better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Make a DataFrame named _X_ that consists of the following predictor columns only: \n",
    "\n",
    "- city\n",
    "- beds\n",
    "- baths\n",
    "- sq__ft\n",
    "- type  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Variables (a.k.a. One-hot encoded variables)\n",
    "\n",
    "---\n",
    "\n",
    "When building a regression model is important to be cautious with categorical variables, which represent distinct groups or categories. If put in a regression \"as-is,\" categorical variables represented as integers will be treated as **continuous** variables.\n",
    "\n",
    "That is to say, instead of the value \"3\" having a different effect on the estimation than group \"1\" it will estimate literally 3 times more than group 1. \n",
    "\n",
    "For example, say we have a problem where occupation category \"1\" represents \"analyst\" and occupation category \"3\" represents \"barista\", and our target variable is salary. If we leave this as a column of integers then barista will always have `beta*3` the effect of analyst.\n",
    "\n",
    "This will not help our regression model and make the interpretation of the coefficient nonsensical. Instead, we can represent the categories as multiple \"dummy coded\" columns.\n",
    "\n",
    "There are several ways to dummy-encode a columns' values in Python. \n",
    "\n",
    "- You can manually create new columns where each value gets it's own column. If the value is present that row gets a `1` otherwise it gets a `0`.\n",
    "- You can use `pd.get_dummies` function. This does not work well once you have a test set. Do not use it.\n",
    "- Use Scikit-learn's (version 1.0 or higher) `OneHotEncoder` class. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. One-hot encode categorical variables\n",
    "\n",
    "Use the OneHotEncoder class to dummy encode  the nominal (categorical) columns. \n",
    "\n",
    "These columns will generally come to you as object (string or categorical) columns, but they might also be encoded as a numerical dtype. \n",
    "\n",
    "Save the resulting DataFrame as a new variable.\n",
    "\n",
    "\n",
    "**Make sure you are using scikit-learn version 1.0+** Earlier versions could give you some issues.\n",
    "\n",
    ">Remember that `df.value_counts()` can help you see the count of each of the values in a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Does your DataFrame look how you expect? Check with `.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### A Word of Caution When Creating Dummies\n",
    "\n",
    "Let's touch on precautions we should take when dummy coding.\n",
    "\n",
    "**If you convert a categorical variable into dummy variables, you want to turn a variable with K categories into K-1 features.**\n",
    "\n",
    "> **Scenario 1:** Suppose we're working with the variable \"sex\" or \"gender\" with values \"M\" and \"F\". \n",
    "\n",
    "You should include in your model only one variable for \"sex = F\" which takes on 1 if sex is female and 0 if sex is not female! Rather than saying \"a one unit change in X,\" the coefficient associated with \"sex = F\" is interpreted as the average change in Y when sex = F relative to when sex = M.\n",
    "\n",
    "| Female | Male | \n",
    "|-------|------|\n",
    "| 0 | 1 | \n",
    "| 1 | 0 |\n",
    "| 0 | 1 |\n",
    "| 1 | 0 |\n",
    "| 1 | 0 |\n",
    "_As we can see a 1 in the female column indicates a 0 in the male column. And so, we have two columns stating the same information in different ways._\n",
    "\n",
    "> Scenario 2: Suppose we're modeling revenue at a bar for each of the days of the week. We have a column with strings identifying which day of the week this observation occured in.\n",
    "\n",
    "We might include six of the days as their own variables: \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\". **But not all 7 days.**  \n",
    "\n",
    "|Monday | Tuesday | Wednesday | Thursday | Friday | Saturday | \n",
    "|-------|---------|-----------|----------|--------|----------|\n",
    "| 1     | 0       |0          |      0   |0       | 0        | \n",
    "| 0     | 1       |0          |      0   |0       | 0        | \n",
    "| 0     | 0       |1          |      0   |0       | 0        | \n",
    "| 0     | 0       |0          |      1   |0       | 0        | \n",
    "| 0     | 0       |0          |      0   |1       | 0        | \n",
    "| 0     | 0       |0          |      0   |0       | 1        | \n",
    "| 0     | 0       |0          |      0   |0       | 0        | \n",
    "\n",
    "_As humans we can infer from the last row that if its is not Monday, Tusday, Wednesday, Thursday, Friday or Saturday than it must be Sunday. Models work the same way._\n",
    "\n",
    "The coefficient for Monday is then interpreted as the average change in revenue when \"day = Monday\" relative to \"day = Sunday.\" The coefficient for Tuesday is interpreted in the average change in revenue when \"day = Tuesday\" relative to \"day = Sunday\" and so on.\n",
    "\n",
    "The category you leave out, which the other columns are *relative to* is often referred to as the **reference category**.\n",
    "\n",
    "One note here, when using an algorithm that regularizes input values, some commentators argue you should not drop any values, because then they are not subject to regularization. There is no perfect solution to this issue. \n",
    "\n",
    "If you do not care about inference, you may decide not to drop a column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Drop one of the columns resulting from OneHotEncoding so you can do inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Using scikit-learn, build what you think will be a strong model with multiple predictors for`price`. \n",
    "\n",
    "The features are your choice, but *include at least three*. At least one should be the dummy-coded columns (either `type` or a new one you engineer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Plot the true price vs. the predicted price to evaluate your model visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. List the five assumptions for a multiple linear regression model \n",
    "If you want a good-performing model that you can do inference on (assuming there is signal in your data).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Pick at least two assumptions and articulate whether or not you believe them to be met  for your model and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. [Bonus] Generate a table showing the point estimates, standard errors, t-scores, p-values, and 95% confidence intervals for the same model. \n",
    "\n",
    "Scikit-learn does not have this functionality built in, but statsmodels does in the `summary` method.  \n",
    "\n",
    "To fit the statsmodels model use something like the following.  There is one big caveat here, however!  `statsmodels.OLS` does _not_ add an intercept to your model, so you will need to do this explicitly by adding a column filled with the number 1 to your X matrix\n",
    "\n",
    "```python\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# check out the add_constant method\n",
    "\n",
    "# The default here is Linear Regression (ordinary least squares regression OLS)\n",
    "\n",
    "model = sm.OLS(y,X).fit()\n",
    "# ...\n",
    "\n",
    "```\n",
    "\n",
    "Write a few sentences interpreting some of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. [Bonus] Test and/or validation sets\n",
    "\n",
    "Note that we haven't used a test set or cross validation in this project. If you're looking for more practice add one or both of those to get a better feel for how your model generalizes. How do your models perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A: "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
